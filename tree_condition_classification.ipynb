{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e316146f-c5ca-470b-9405-1d72e17240b6",
   "metadata": {},
   "source": [
    "### Paper parameters \n",
    "- 60% train, 40% split into val and test\n",
    "- Images randomly cropped to 300x300 pixels\n",
    "- 4 classes for classification\n",
    "- cross entropy loss\n",
    "- 15 epochs\n",
    "- 0.001 learning rate (start, then annealing cosine scheduler)\n",
    "- Sliding window of 300x300 with a stride of 50 pixels\n",
    "    - Softmax per window. Highest class probability is one vote if probability higher than threshold.\n",
    "    - Final prediction is the condition with highest number of votes across all windows\n",
    "    - Probability thresholds of 0.7. No probability, then data is dropped \n",
    "\n",
    "### Paper results\n",
    "- field/ no field classifier: Finally, training a CNN to classify\n",
    "field/not field improved precision to 0.98 and lowered recall\n",
    "slightly to 0.95 â€” a worthwhile trade-of\n",
    "- \"Maize had the lowest F1 score under both WebCC\n",
    "and iNaturalist (62% and 68%, respectively), followed by\n",
    "sugarcane (62% and 76%). The low performance is likely\n",
    "due to the more visual similarities between the two crops at\n",
    "the early-growth stage as well as their similar height. Meanwhile, rice has short and bright green leaves and cassava has\n",
    "a palmate leaf structure and is grown more separately, both\n",
    "more visually distinctive from the street\".\n",
    "    - And we discriminate from subtle differences in leaf color and amount for very different tree species.\n",
    "- \"The top performing model trained on the Expert labeled dataset achieved 82% accuracy when directly classifying the whole image, 90% with sliding windows but no\n",
    "MHP threshold, and 93% with a 0.90 MHP threshold\"\n",
    "\n",
    "### Useful references\n",
    "+ Resnet paper: https://arxiv.org/pdf/1512.03385.pdf\n",
    "+ Croptypes paper: https://arxiv.org/pdf/2309.05930.pdf\n",
    "+ Input needed for resnet50: https://pytorch.org/hub/pytorch_vision_resnet/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b6d6df3-0d58-4feb-b783-65cae25d4dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split, Subset\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Additional Setup to use Tensorboard\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42345aaf-a146-451f-822d-ccc225652a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function\n",
    "def get_class_distribution(dataset):\n",
    "    count_dict = dict()\n",
    "    \n",
    "    for input, label in dataset:\n",
    "        count_dict[label] = count_dict.get(label, 0) + 1\n",
    "    return count_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558dea98-68d5-4b2b-a48d-bb952c365eee",
   "metadata": {},
   "source": [
    "Use ordered_trees_classified.zip to get te correct folder order to work with the code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "73a77052-330f-4e03-b440-a20dba2a0140",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.CenterCrop((300, 324)),  # Cut out the image to 300x324 | To be further cut up later\n",
    "    transforms.ToTensor(),           # Convert the image to a PyTorch tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize the image\n",
    "])\n",
    "data_path = \"trees_classified\"\n",
    "label_transform = {0:\"Matig\", 1:\"Redelijk\", 2:\"Slecht\", 3:\"Goed\", 4:\"Dood\", 5:\"Zeer-Slecht\"}  # Dataset sorted on most samples first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b8e7964d-e456-4824-84d4-53a818350ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.ImageFolder(root=data_path, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "14a7145e-436c-4ff8-96d4-acf6a68f1c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 9553, 1: 8104, 2: 947, 3: 289, 4: 116, 5: 87}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See how unbalanced the classes are before balancing\n",
    "get_class_distribution(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5749a7a5-81f8-43aa-9a06-39741857e1ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1000, 1: 1000, 2: 947}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Balance the classes by randomly samling class_limit samples from each class\n",
    "\n",
    "class_limit = 1000\n",
    "num_classes = 3  # specify how many classes we use. This determines output dimension of the model.\n",
    "\n",
    "#idx_class1 = [i for i, label in enumerate(dataset.targets) if label == 1]  # Add one if samples are weighted based on class imbalance\n",
    "idx_class0 = [i for i, label in enumerate(dataset.targets) if label == 0]\n",
    "idx_class1 = [i for i, label in enumerate(dataset.targets) if label == 1]\n",
    "idx_class2 = [i for i, label in enumerate(dataset.targets) if label == 2]\n",
    "\n",
    "\n",
    "np.random.shuffle(idx_class0)\n",
    "np.random.shuffle(idx_class1)\n",
    "idx_class0_limit = idx_class0[:class_limit]\n",
    "idx_class1_limit = idx_class1[:class_limit]\n",
    "# print(len(idx_class1_limit))\n",
    "# print(len(idx_class0))\n",
    "\n",
    "idx_dataset_limited = np.concatenate((idx_class0_limit, idx_class1_limit, idx_class2))\n",
    "# print(len(idx_dataset_limited))\n",
    "\n",
    "balanced_dataset = Subset(dataset, idx_dataset_limited)\n",
    "\n",
    "# Print the balanced dataset distribution\n",
    "get_class_distribution(balanced_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f209f7fa-ae3d-4f8b-a25f-3f1c580f56be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(balanced_dataset))\n",
    "test_size = len(balanced_dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(balanced_dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "996866e2-340b-442b-8c76-3ba35908f5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "622c3a3a-d1d5-4598-9a45-bc9c8908bde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50 = models.resnet50(weights='DEFAULT')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aa5e780f-dc7c-48c3-9aae-1b17a8590de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, net, optimizer, criterion, device):\n",
    "    \"\"\"\n",
    "    Trains network for one epoch in batches.\n",
    "\n",
    "    Args:\n",
    "        train_loader: Data loader for training set.\n",
    "        net: Neural network model.\n",
    "        optimizer: Optimizer (e.g. SGD).\n",
    "        criterion: Loss function (e.g. cross-entropy loss).\n",
    "    \"\"\"\n",
    "\n",
    "    avg_loss = 0.\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    net.train()\n",
    "\n",
    "    # iterate through batches\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # zero teh parameters of optimizer\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # fwd + back + opti\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # keep track of loss and acc\n",
    "        avg_loss += loss\n",
    "        _, predicted = torch.max(outputs.data,1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return avg_loss/len(train_loader), 100 * correct/total\n",
    "\n",
    "def test(test_loader, net, criterion, device):\n",
    "    avg_loss = 0.\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    net.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            avg_loss += loss\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    return avg_loss/len(train_loader), 100 * correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5c84f90e-bbc8-4fb2-9dbc-eb7bca1a587b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f3e7d7d9-fa2b-4dbb-94d3-b5b4a9f80dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/15 [02:20<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 21\u001b[0m\n\u001b[0;32m     17\u001b[0m patience_cnt \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(epochs)):  \u001b[38;5;66;03m# loop over the dataset multiple times\u001b[39;00m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;66;03m# Train on data\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m     train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresnet50\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;66;03m# Test on data\u001b[39;00m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;66;03m#val_loss, val_acc = test(val_loader, resnet50, criterion, device)\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \n\u001b[0;32m     26\u001b[0m     \u001b[38;5;66;03m# Write metrics to Tensorboard\u001b[39;00m\n\u001b[0;32m     27\u001b[0m     writer\u001b[38;5;241m.\u001b[39madd_scalars(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss\u001b[39m\u001b[38;5;124m\"\u001b[39m, {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain\u001b[39m\u001b[38;5;124m'\u001b[39m: train_loss, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest\u001b[39m\u001b[38;5;124m'\u001b[39m:val_loss}, epoch)\n",
      "Cell \u001b[1;32mIn[36], line 29\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(train_loader, net, optimizer, criterion, device)\u001b[0m\n\u001b[0;32m     27\u001b[0m outputs \u001b[38;5;241m=\u001b[39m net(inputs)\n\u001b[0;32m     28\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m---> 29\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# keep track of loss and acc\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Niek\\Documents\\TU Delft\\Master Robotics\\Deep Learning\\croptypes\\venv\\lib\\site-packages\\torch\\_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    521\u001b[0m     )\n\u001b[1;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Niek\\Documents\\TU Delft\\Master Robotics\\Deep Learning\\croptypes\\venv\\lib\\site-packages\\torch\\autograd\\__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter(log_dir=\"./runs_condition/\")\n",
    "\n",
    "resnet50.fc = nn.Linear(resnet50.fc.in_features, num_classes)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(resnet50.fc.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 15\n",
    "resnet50.to(device)\n",
    "\n",
    "# Set the number of epochs to for training\n",
    "epochs = 15\n",
    "\n",
    "patience = 20\n",
    "\n",
    "train_acc_best = 0\n",
    "patience_cnt = 0\n",
    "\n",
    "for epoch in tqdm(range(epochs)):  # loop over the dataset multiple times\n",
    "    # Train on data\n",
    "    train_loss, train_acc = train(train_loader, resnet50, optimizer, criterion, device)\n",
    "\n",
    "    # Test on data\n",
    "    #val_loss, val_acc = test(val_loader, resnet50, criterion, device)\n",
    "\n",
    "    # Write metrics to Tensorboard\n",
    "    writer.add_scalars(\"Loss\", {'Train': train_loss, 'Test':val_loss}, epoch)\n",
    "    writer.add_scalars('Accuracy', {'Train': train_acc,'Test':val_acc} , epoch)\n",
    "\n",
    "\n",
    "    if train_acc > train_acc_best:\n",
    "      train_acc_best = train_acc\n",
    "      patience_cnt = 0\n",
    "      best_model_wts = resnet50.state_dict()\n",
    "\n",
    "    else:\n",
    "      patience_cnt += 1\n",
    "      if patience_cnt == patience:\n",
    "        break\n",
    "    # print(f\"Current loss {train_loss} at epoch {epoch}\")\n",
    "\n",
    "\n",
    "print('Finished Training')\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de215daf-2307-4c04-96f3-7c88ee5885b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open Tensorboard\n",
    "%tensorboard --logdir runs_condition/\n",
    "\n",
    "# For local users only: uncomment the last line, run this cell once and wait for\n",
    "# it to time out, run this cell a second time and you should see the board.\n",
    "# %tensorboard --logdir runs/ --host localhost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcade1d-256f-4d88-8179-ad97fa3f1338",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50.load_state_dict(best_model_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ad9d96-66c1-41b6-b203-2530873f96f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(resnet50.state_dict(), \"resnet50_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b195e1c-c9e1-4009-8742-f1ee29891046",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "resnet50.eval()\n",
    "\n",
    "\n",
    "# Iterate through the test data\n",
    "for inputs, labels in test_loader:\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    \n",
    "    # Forward pass\n",
    "    with torch.no_grad():\n",
    "        outputs = resnet50(inputs)\n",
    "    \n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    \n",
    "    # Append true labels and predicted labels\n",
    "    true_labels.extend(labels.cpu().numpy())\n",
    "    predicted_labels.extend(predicted.cpu().numpy())\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "report = classification_report(true_labels, predicted_labels)\n",
    "\n",
    "# Print the evaluation report\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac50997-d971-472b-bf9a-4d7d8ad00195",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d05a4f-9590-4e41-b75e-e47b7ebc0a13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c6e5bd-9ae7-4f10-ae6a-5003f3f5c36b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d4e43c-673a-486e-8103-16c1ba979aaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
